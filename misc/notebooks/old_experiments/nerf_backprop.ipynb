{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-08-23T23:58:40.376328Z",
     "start_time": "2024-08-23T23:58:40.373606Z"
    }
   },
   "source": [
    "from pathlib import Path\n",
    "import yaml\n",
    "import json\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from nerfstudio.model_components.ray_generators import RayGenerator\n",
    "\n",
    "torch.cuda.init()\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "\n",
    "from nerfstudio.configs.method_configs import all_methods\n",
    "from nerfstudio.engine.trainer import TrainerConfig\n",
    "from nerfstudio.pipelines.base_pipeline import Pipeline\n",
    "from nerfstudio.cameras.cameras import Cameras, CameraType"
   ],
   "outputs": [],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-23T23:48:00.567973Z",
     "start_time": "2024-08-23T23:48:00.565856Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "b1649cc3141fac46",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-23T23:48:04.436291Z",
     "start_time": "2024-08-23T23:48:04.432571Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def setup_trainable_pipeline(config_path: Path) -> Pipeline:\n",
    "    config = yaml.load(config_path.read_text(), Loader=yaml.Loader)\n",
    "    assert isinstance(config, TrainerConfig)\n",
    "    \n",
    "    config.pipeline.datamanager._target = all_methods[config.method_name].pipeline.datamanager._target\n",
    "    config.load_dir = config.get_checkpoint_dir()\n",
    "    \n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    pipeline = config.pipeline.setup(device=device, test_mode=\"inference\")\n",
    "    assert isinstance(pipeline, Pipeline)\n",
    "    \n",
    "    return pipeline\n",
    "\n",
    "def image_to_tensor(image_path, device) -> torch.Tensor:\n",
    "    # Open the image using PIL\n",
    "    image = Image.open(image_path).convert(\"RGB\")\n",
    "\n",
    "    # Define the transform to convert the image to a PyTorch tensor\n",
    "    transform = transforms.ToTensor()  # This will convert to a tensor with shape (C, H, W)\n",
    "\n",
    "    # Apply the transform\n",
    "    tensor = transform(image)  # Shape will be (3, 512, 512)\n",
    "\n",
    "    # Permute the tensor to get shape (512, 512, 3)\n",
    "    tensor = tensor.permute(1, 2, 0).to(device)\n",
    "\n",
    "    return tensor.detach().requires_grad_(False)"
   ],
   "id": "d9837bb7615370c5",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-23T23:48:01.002720Z",
     "start_time": "2024-08-23T23:48:01.001362Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "4d0184ff3a357199",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-23T23:48:11.826Z",
     "start_time": "2024-08-23T23:48:11.294031Z"
    }
   },
   "cell_type": "code",
   "source": [
    "config_path = Path(\n",
    "    \"/n/home10/dpodolskyi/neural-registration/outputs/0_065_cat5_2/instant-ngp/2024-08-20_140044/config.yml\")\n",
    "\n",
    "checkpoint_path = \"/n/home10/dpodolskyi/neural-registration/outputs/0_065_cat5_2/instant-ngp/2024-08-20_140044/nerfstudio_models/step-000018000.ckpt\"\n",
    "\n",
    "train_pipeline = setup_trainable_pipeline(config_path)\n",
    "nerf_model = train_pipeline.model\n",
    "nerf_device = nerf_model.device"
   ],
   "id": "c5ec2a7ab035d4b3",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-23T23:22:03.613219Z",
     "start_time": "2024-08-23T23:22:03.611832Z"
    }
   },
   "cell_type": "code",
   "source": "train_pipeline.datamanager",
   "id": "fc5c4fdf87551577",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "9fa7925fbcd721"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "f3284b13d256bb20"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-23T23:22:03.696512Z",
     "start_time": "2024-08-23T23:22:03.695131Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "54dfe3ab2554e110",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-23T23:49:08.596933Z",
     "start_time": "2024-08-23T23:49:08.594697Z"
    }
   },
   "cell_type": "code",
   "source": "torch.cuda.empty_cache()",
   "id": "25d719cecfc6acfd",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-23T23:48:16.945090Z",
     "start_time": "2024-08-23T23:48:16.939747Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# custom nerfstudio transformation\n",
    "dataparser_transforms_path = Path(\n",
    "    \"/n/home10/dpodolskyi/neural-registration/outputs/0_065_cat5_2/instant-ngp/2024-08-20_140044/dataparser_transforms.json\")\n",
    "\n",
    "with open(dataparser_transforms_path, \"r\") as f:\n",
    "    dataparser_transform = json.load(f)\n",
    "\n",
    "dataparser_matrix = torch.tensor(dataparser_transform[\"transform\"], dtype=torch.float32)\n",
    "dataparser_matrix = np.vstack((dataparser_matrix, np.array([[0, 0, 0, 1]])))\n",
    "dataparser_scale = dataparser_transform[\"scale\"]\n"
   ],
   "id": "be825c37cbce9f56",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-23T23:48:18.568054Z",
     "start_time": "2024-08-23T23:48:18.535508Z"
    }
   },
   "cell_type": "code",
   "source": [
    "data_transform_matrix = np.array([\n",
    "    [-0.16551750084030392, 0.17173068552312126, -0.9711398089695112, -80.73672706466026],\n",
    "    [-0.9756847655052445, 0.11494663876681419, 0.18661861803471735, 15.51473463480075],\n",
    "    [0.14367740002017088, 0.9784149640546033, 0.14852933325600515, 12.348141976499424],\n",
    "    [0, 0, 0, 1],\n",
    "])\n",
    "\n",
    "camera_params = {\n",
    "    \"camera_angle_x\": 0.5235987755982988,\n",
    "    \"camera_angle_y\": 0.5235987755982988,\n",
    "    \"fl_x\": 955.4050067376327,\n",
    "    \"fl_y\": 955.4050067376327,\n",
    "    \"k1\": 0,\n",
    "    \"k2\": 0,\n",
    "    \"k3\": 0,\n",
    "    \"k4\": 0,\n",
    "    \"p1\": 0,\n",
    "    \"p2\": 0,\n",
    "    \"is_fisheye\": False,\n",
    "    \"cx\": 256.0,\n",
    "    \"cy\": 256.0,\n",
    "    \"w\": 512,\n",
    "    \"h\": 512,\n",
    "    \"aabb_scale\": 32,\n",
    "}\n",
    "\n",
    "final_matrix = np.dot(dataparser_matrix, data_transform_matrix)\n",
    "final_matrix[:3, 3] = final_matrix[:3, 3] * dataparser_scale\n",
    "final_matrix = nn.Parameter(torch.tensor(final_matrix[:3, :4], dtype=torch.float32).unsqueeze(0), requires_grad=True).to(nerf_device)\n",
    "final_matrix, final_matrix.shape\n",
    "\n",
    "# should look like this:\n",
    "# actual_transform_matrix = np.array([\n",
    "#     [-0.2205035537481308, -0.21815498173236847, -0.9506769180297852, -0.11759857088327408],\n",
    "#     [-0.9667345285415649, 0.17840947210788727, 0.1832878142595291, 0.23202396929264069],\n",
    "#     [0.129624605178833, 0.9594677686691284, -0.2502378523349762, -0.26915040612220764],\n",
    "# ])"
   ],
   "id": "ca42dbb60b006c14",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[-0.2205, -0.2182, -0.9507, -0.1176],\n",
       "          [-0.9667,  0.1784,  0.1833,  0.2320],\n",
       "          [ 0.1296,  0.9595, -0.2502, -0.2692]]], device='cuda:0',\n",
       "        grad_fn=<ToCopyBackward0>),\n",
       " torch.Size([1, 3, 4]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-24T00:04:42.832801Z",
     "start_time": "2024-08-24T00:04:42.830033Z"
    }
   },
   "cell_type": "code",
   "source": [
    "camera = Cameras(\n",
    "    camera_to_worlds=final_matrix, # 1x3x4 tensor\n",
    "    fx=camera_params[\"fl_x\"],\n",
    "    fy=camera_params[\"fl_y\"],\n",
    "    cx=camera_params[\"cx\"],\n",
    "    cy=camera_params[\"cy\"],\n",
    "    camera_type=CameraType.PERSPECTIVE,\n",
    "    height=camera_params[\"h\"],\n",
    "    width=camera_params[\"w\"],\n",
    ").to(nerf_device)"
   ],
   "id": "4c889922a814fdec",
   "outputs": [],
   "execution_count": 35
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-24T00:04:43.332438Z",
     "start_time": "2024-08-24T00:04:43.328143Z"
    }
   },
   "cell_type": "code",
   "source": "rays_gen = RayGenerator(camera).to(nerf_device)",
   "id": "5c66e1aab4fb6f1",
   "outputs": [],
   "execution_count": 36
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "b1b63ae8f698ca9f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "a97ffadcc381f4d5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-24T00:04:44.680495Z",
     "start_time": "2024-08-24T00:04:44.676617Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# indices = torch.tensor(0).to(nerf_device)\n",
    "ray_indices = torch.tensor([[0, 0, 0]], device=nerf_device)\n",
    "# ray_bundle = camera.generate_rays(0).to(nerf_device)\n",
    "ray_bundle = rays_gen(ray_indices)"
   ],
   "id": "b391191abad2188b",
   "outputs": [],
   "execution_count": 37
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-24T00:04:47.481150Z",
     "start_time": "2024-08-24T00:04:47.478289Z"
    }
   },
   "cell_type": "code",
   "source": "ray_bundle.origins.shape, ray_bundle.directions.shape, ray_bundle.shape, ray_bundle.origins.device, ray_bundle.directions.device",
   "id": "d174285e1b4c455c",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 3]),\n",
       " torch.Size([1, 3]),\n",
       " torch.Size([1]),\n",
       " device(type='cuda', index=0),\n",
       " device(type='cuda', index=0))"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 38
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-24T00:04:56.604275Z",
     "start_time": "2024-08-24T00:04:56.468865Z"
    }
   },
   "cell_type": "code",
   "source": "nerf_model.get_outputs_for_camera(camera)",
   "id": "c94ab24009cdfac5",
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "cannot reshape tensor of 0 elements into shape [0, -1] because the unspecified dimension size -1 can be any value and is ambiguous",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[39], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43mnerf_model\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_outputs_for_camera\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcamera\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.conda/envs/nerf-inversion/lib/python3.8/site-packages/torch/utils/_contextlib.py:115\u001B[0m, in \u001B[0;36mcontext_decorator.<locals>.decorate_context\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    112\u001B[0m \u001B[38;5;129m@functools\u001B[39m\u001B[38;5;241m.\u001B[39mwraps(func)\n\u001B[1;32m    113\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mdecorate_context\u001B[39m(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[1;32m    114\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m ctx_factory():\n\u001B[0;32m--> 115\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.conda/envs/nerf-inversion/lib/python3.8/site-packages/nerfstudio/models/base_model.py:173\u001B[0m, in \u001B[0;36mModel.get_outputs_for_camera\u001B[0;34m(self, camera, obb_box)\u001B[0m\n\u001B[1;32m    165\u001B[0m \u001B[38;5;129m@torch\u001B[39m\u001B[38;5;241m.\u001B[39mno_grad()\n\u001B[1;32m    166\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mget_outputs_for_camera\u001B[39m(\u001B[38;5;28mself\u001B[39m, camera: Cameras, obb_box: Optional[OrientedBox] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Dict[\u001B[38;5;28mstr\u001B[39m, torch\u001B[38;5;241m.\u001B[39mTensor]:\n\u001B[1;32m    167\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Takes in a camera, generates the raybundle, and computes the output of the model.\u001B[39;00m\n\u001B[1;32m    168\u001B[0m \u001B[38;5;124;03m    Assumes a ray-based model.\u001B[39;00m\n\u001B[1;32m    169\u001B[0m \n\u001B[1;32m    170\u001B[0m \u001B[38;5;124;03m    Args:\u001B[39;00m\n\u001B[1;32m    171\u001B[0m \u001B[38;5;124;03m        camera: generates raybundle\u001B[39;00m\n\u001B[1;32m    172\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m--> 173\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_outputs_for_camera_ray_bundle\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    174\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcamera\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgenerate_rays\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcamera_indices\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkeep_shape\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mobb_box\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mobb_box\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    175\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.conda/envs/nerf-inversion/lib/python3.8/site-packages/torch/utils/_contextlib.py:115\u001B[0m, in \u001B[0;36mcontext_decorator.<locals>.decorate_context\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    112\u001B[0m \u001B[38;5;129m@functools\u001B[39m\u001B[38;5;241m.\u001B[39mwraps(func)\n\u001B[1;32m    113\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mdecorate_context\u001B[39m(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[1;32m    114\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m ctx_factory():\n\u001B[0;32m--> 115\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.conda/envs/nerf-inversion/lib/python3.8/site-packages/nerfstudio/models/base_model.py:195\u001B[0m, in \u001B[0;36mModel.get_outputs_for_camera_ray_bundle\u001B[0;34m(self, camera_ray_bundle)\u001B[0m\n\u001B[1;32m    193\u001B[0m \u001B[38;5;66;03m# move the chunk inputs to the model device\u001B[39;00m\n\u001B[1;32m    194\u001B[0m ray_bundle \u001B[38;5;241m=\u001B[39m ray_bundle\u001B[38;5;241m.\u001B[39mto(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdevice)\n\u001B[0;32m--> 195\u001B[0m outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mforward\u001B[49m\u001B[43m(\u001B[49m\u001B[43mray_bundle\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mray_bundle\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    196\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m output_name, output \u001B[38;5;129;01min\u001B[39;00m outputs\u001B[38;5;241m.\u001B[39mitems():  \u001B[38;5;66;03m# type: ignore\u001B[39;00m\n\u001B[1;32m    197\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(output, torch\u001B[38;5;241m.\u001B[39mTensor):\n\u001B[1;32m    198\u001B[0m         \u001B[38;5;66;03m# TODO: handle lists of tensors as well\u001B[39;00m\n",
      "File \u001B[0;32m~/.conda/envs/nerf-inversion/lib/python3.8/site-packages/nerfstudio/models/base_model.py:143\u001B[0m, in \u001B[0;36mModel.forward\u001B[0;34m(self, ray_bundle)\u001B[0m\n\u001B[1;32m    140\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcollider \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    141\u001B[0m     ray_bundle \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcollider(ray_bundle)\n\u001B[0;32m--> 143\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_outputs\u001B[49m\u001B[43m(\u001B[49m\u001B[43mray_bundle\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.conda/envs/nerf-inversion/lib/python3.8/site-packages/nerfstudio/models/instant_ngp.py:175\u001B[0m, in \u001B[0;36mNGPModel.get_outputs\u001B[0;34m(self, ray_bundle)\u001B[0m\n\u001B[1;32m    172\u001B[0m num_rays \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlen\u001B[39m(ray_bundle)\n\u001B[1;32m    174\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mno_grad():\n\u001B[0;32m--> 175\u001B[0m     ray_samples, ray_indices \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msampler\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    176\u001B[0m \u001B[43m        \u001B[49m\u001B[43mray_bundle\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mray_bundle\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    177\u001B[0m \u001B[43m        \u001B[49m\u001B[43mnear_plane\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconfig\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnear_plane\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    178\u001B[0m \u001B[43m        \u001B[49m\u001B[43mfar_plane\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconfig\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfar_plane\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    179\u001B[0m \u001B[43m        \u001B[49m\u001B[43mrender_step_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconfig\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrender_step_size\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    180\u001B[0m \u001B[43m        \u001B[49m\u001B[43malpha_thre\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconfig\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43malpha_thre\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    181\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcone_angle\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconfig\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcone_angle\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    182\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    184\u001B[0m field_outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfield(ray_samples)\n\u001B[1;32m    185\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconfig\u001B[38;5;241m.\u001B[39muse_gradient_scaling:\n",
      "File \u001B[0;32m~/.conda/envs/nerf-inversion/lib/python3.8/site-packages/torch/nn/modules/module.py:1518\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1516\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1517\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1518\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.conda/envs/nerf-inversion/lib/python3.8/site-packages/torch/nn/modules/module.py:1527\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1522\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1523\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1524\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1525\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1526\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1527\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1529\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1530\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m~/.conda/envs/nerf-inversion/lib/python3.8/site-packages/nerfstudio/model_components/ray_samplers.py:482\u001B[0m, in \u001B[0;36mVolumetricSampler.forward\u001B[0;34m(self, ray_bundle, render_step_size, near_plane, far_plane, alpha_thre, cone_angle)\u001B[0m\n\u001B[1;32m    480\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    481\u001B[0m     camera_indices \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m--> 482\u001B[0m ray_indices, starts, ends \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moccupancy_grid\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msampling\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    483\u001B[0m \u001B[43m    \u001B[49m\u001B[43mrays_o\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrays_o\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    484\u001B[0m \u001B[43m    \u001B[49m\u001B[43mrays_d\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrays_d\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    485\u001B[0m \u001B[43m    \u001B[49m\u001B[43mt_min\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mt_min\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    486\u001B[0m \u001B[43m    \u001B[49m\u001B[43mt_max\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mt_max\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    487\u001B[0m \u001B[43m    \u001B[49m\u001B[43msigma_fn\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_sigma_fn\u001B[49m\u001B[43m(\u001B[49m\u001B[43mrays_o\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mrays_d\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtimes\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    488\u001B[0m \u001B[43m    \u001B[49m\u001B[43mrender_step_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrender_step_size\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    489\u001B[0m \u001B[43m    \u001B[49m\u001B[43mnear_plane\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mnear_plane\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    490\u001B[0m \u001B[43m    \u001B[49m\u001B[43mfar_plane\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfar_plane\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    491\u001B[0m \u001B[43m    \u001B[49m\u001B[43mstratified\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtraining\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    492\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcone_angle\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcone_angle\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    493\u001B[0m \u001B[43m    \u001B[49m\u001B[43malpha_thre\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43malpha_thre\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    494\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    495\u001B[0m num_samples \u001B[38;5;241m=\u001B[39m starts\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m0\u001B[39m]\n\u001B[1;32m    496\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m num_samples \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[1;32m    497\u001B[0m     \u001B[38;5;66;03m# create a single fake sample and update packed_info accordingly\u001B[39;00m\n\u001B[1;32m    498\u001B[0m     \u001B[38;5;66;03m# this says the last ray in packed_info has 1 sample, which starts and ends at 1\u001B[39;00m\n",
      "File \u001B[0;32m~/.conda/envs/nerf-inversion/lib/python3.8/site-packages/torch/utils/_contextlib.py:115\u001B[0m, in \u001B[0;36mcontext_decorator.<locals>.decorate_context\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    112\u001B[0m \u001B[38;5;129m@functools\u001B[39m\u001B[38;5;241m.\u001B[39mwraps(func)\n\u001B[1;32m    113\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mdecorate_context\u001B[39m(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[1;32m    114\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m ctx_factory():\n\u001B[0;32m--> 115\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.conda/envs/nerf-inversion/lib/python3.8/site-packages/nerfacc/estimators/occ_grid.py:187\u001B[0m, in \u001B[0;36mOccGridEstimator.sampling\u001B[0;34m(self, rays_o, rays_d, sigma_fn, alpha_fn, near_plane, far_plane, t_min, t_max, render_step_size, early_stop_eps, alpha_thre, stratified, cone_angle)\u001B[0m\n\u001B[1;32m    185\u001B[0m \u001B[38;5;66;03m# Compute visibility of the samples, and filter out invisible samples\u001B[39;00m\n\u001B[1;32m    186\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m sigma_fn \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m--> 187\u001B[0m     sigmas \u001B[38;5;241m=\u001B[39m \u001B[43msigma_fn\u001B[49m\u001B[43m(\u001B[49m\u001B[43mt_starts\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mt_ends\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mray_indices\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    188\u001B[0m     \u001B[38;5;28;01massert\u001B[39;00m (\n\u001B[1;32m    189\u001B[0m         sigmas\u001B[38;5;241m.\u001B[39mshape \u001B[38;5;241m==\u001B[39m t_starts\u001B[38;5;241m.\u001B[39mshape\n\u001B[1;32m    190\u001B[0m     ), \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msigmas must have shape of (N,)! Got \u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(sigmas\u001B[38;5;241m.\u001B[39mshape)\n\u001B[1;32m    191\u001B[0m     masks \u001B[38;5;241m=\u001B[39m render_visibility_from_density(\n\u001B[1;32m    192\u001B[0m         t_starts\u001B[38;5;241m=\u001B[39mt_starts,\n\u001B[1;32m    193\u001B[0m         t_ends\u001B[38;5;241m=\u001B[39mt_ends,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    197\u001B[0m         alpha_thre\u001B[38;5;241m=\u001B[39malpha_thre,\n\u001B[1;32m    198\u001B[0m     )\n",
      "File \u001B[0;32m~/.conda/envs/nerf-inversion/lib/python3.8/site-packages/nerfstudio/model_components/ray_samplers.py:428\u001B[0m, in \u001B[0;36mVolumetricSampler.get_sigma_fn.<locals>.sigma_fn\u001B[0;34m(t_starts, t_ends, ray_indices)\u001B[0m\n\u001B[1;32m    426\u001B[0m positions \u001B[38;5;241m=\u001B[39m t_origins \u001B[38;5;241m+\u001B[39m t_dirs \u001B[38;5;241m*\u001B[39m (t_starts \u001B[38;5;241m+\u001B[39m t_ends)[:, \u001B[38;5;28;01mNone\u001B[39;00m] \u001B[38;5;241m/\u001B[39m \u001B[38;5;241m2.0\u001B[39m\n\u001B[1;32m    427\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m times \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m--> 428\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mdensity_fn\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpositions\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39msqueeze(\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m)\n\u001B[1;32m    429\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m density_fn(positions, times[ray_indices])\u001B[38;5;241m.\u001B[39msqueeze(\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m)\n",
      "File \u001B[0;32m~/.conda/envs/nerf-inversion/lib/python3.8/site-packages/nerfstudio/fields/base_field.py:67\u001B[0m, in \u001B[0;36mField.density_fn\u001B[0;34m(***failed resolving arguments***)\u001B[0m\n\u001B[1;32m     57\u001B[0m \u001B[38;5;66;03m# Need to figure out a better way to describe positions with a ray.\u001B[39;00m\n\u001B[1;32m     58\u001B[0m ray_samples \u001B[38;5;241m=\u001B[39m RaySamples(\n\u001B[1;32m     59\u001B[0m     frustums\u001B[38;5;241m=\u001B[39mFrustums(\n\u001B[1;32m     60\u001B[0m         origins\u001B[38;5;241m=\u001B[39mpositions,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     65\u001B[0m     )\n\u001B[1;32m     66\u001B[0m )\n\u001B[0;32m---> 67\u001B[0m density, _ \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_density\u001B[49m\u001B[43m(\u001B[49m\u001B[43mray_samples\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     68\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m density\n",
      "File \u001B[0;32m~/.conda/envs/nerf-inversion/lib/python3.8/site-packages/nerfstudio/fields/nerfacto_field.py:219\u001B[0m, in \u001B[0;36mNerfactoField.get_density\u001B[0;34m(self, ray_samples)\u001B[0m\n\u001B[1;32m    217\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_sample_locations\u001B[38;5;241m.\u001B[39mrequires_grad \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[1;32m    218\u001B[0m positions_flat \u001B[38;5;241m=\u001B[39m positions\u001B[38;5;241m.\u001B[39mview(\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m3\u001B[39m)\n\u001B[0;32m--> 219\u001B[0m h \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmlp_base\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpositions_flat\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mview\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mray_samples\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfrustums\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mshape\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m-\u001B[39;49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m    220\u001B[0m density_before_activation, base_mlp_out \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39msplit(h, [\u001B[38;5;241m1\u001B[39m, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgeo_feat_dim], dim\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m)\n\u001B[1;32m    221\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_density_before_activation \u001B[38;5;241m=\u001B[39m density_before_activation\n",
      "\u001B[0;31mRuntimeError\u001B[0m: cannot reshape tensor of 0 elements into shape [0, -1] because the unspecified dimension size -1 can be any value and is ambiguous"
     ]
    }
   ],
   "execution_count": 39
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-23T23:49:20.718065Z",
     "start_time": "2024-08-23T23:49:20.715597Z"
    }
   },
   "cell_type": "code",
   "source": "print(ray_bundle.origins.numel(), ray_bundle.directions.numel())",
   "id": "d6acf76f1acf1c9a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "786432 786432\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "e399149ee01ce591"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "4472defa98415c51"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "2929bd60bb49b45d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "b6bc4ea767a2d884"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "c81597c4963599d5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "863183a9a227060a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "8c397d7433fccf1b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "547488cfe45ba836"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "9665ce2ed58959b5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-23T23:29:48.285650Z",
     "start_time": "2024-08-23T23:29:48.075860Z"
    }
   },
   "cell_type": "code",
   "source": [
    "with torch.no_grad():\n",
    "    outputs = nerf_model.get_outputs_for_camera(camera)\n",
    "    generated_rgb = outputs[\"rgb\"].cpu().numpy()"
   ],
   "id": "89c3a6685980d68f",
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "cannot reshape tensor of 0 elements into shape [0, -1] because the unspecified dimension size -1 can be any value and is ambiguous",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[21], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mno_grad():\n\u001B[0;32m----> 2\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m \u001B[43mnerf_model\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_outputs_for_camera\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcamera\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      3\u001B[0m     generated_rgb \u001B[38;5;241m=\u001B[39m outputs[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mrgb\u001B[39m\u001B[38;5;124m\"\u001B[39m]\u001B[38;5;241m.\u001B[39mcpu()\u001B[38;5;241m.\u001B[39mnumpy()\n",
      "File \u001B[0;32m~/.conda/envs/nerf-inversion/lib/python3.8/site-packages/torch/utils/_contextlib.py:115\u001B[0m, in \u001B[0;36mcontext_decorator.<locals>.decorate_context\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    112\u001B[0m \u001B[38;5;129m@functools\u001B[39m\u001B[38;5;241m.\u001B[39mwraps(func)\n\u001B[1;32m    113\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mdecorate_context\u001B[39m(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[1;32m    114\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m ctx_factory():\n\u001B[0;32m--> 115\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.conda/envs/nerf-inversion/lib/python3.8/site-packages/nerfstudio/models/base_model.py:173\u001B[0m, in \u001B[0;36mModel.get_outputs_for_camera\u001B[0;34m(self, camera, obb_box)\u001B[0m\n\u001B[1;32m    165\u001B[0m \u001B[38;5;129m@torch\u001B[39m\u001B[38;5;241m.\u001B[39mno_grad()\n\u001B[1;32m    166\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mget_outputs_for_camera\u001B[39m(\u001B[38;5;28mself\u001B[39m, camera: Cameras, obb_box: Optional[OrientedBox] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Dict[\u001B[38;5;28mstr\u001B[39m, torch\u001B[38;5;241m.\u001B[39mTensor]:\n\u001B[1;32m    167\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Takes in a camera, generates the raybundle, and computes the output of the model.\u001B[39;00m\n\u001B[1;32m    168\u001B[0m \u001B[38;5;124;03m    Assumes a ray-based model.\u001B[39;00m\n\u001B[1;32m    169\u001B[0m \n\u001B[1;32m    170\u001B[0m \u001B[38;5;124;03m    Args:\u001B[39;00m\n\u001B[1;32m    171\u001B[0m \u001B[38;5;124;03m        camera: generates raybundle\u001B[39;00m\n\u001B[1;32m    172\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m--> 173\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_outputs_for_camera_ray_bundle\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    174\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcamera\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgenerate_rays\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcamera_indices\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkeep_shape\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mobb_box\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mobb_box\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    175\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.conda/envs/nerf-inversion/lib/python3.8/site-packages/torch/utils/_contextlib.py:115\u001B[0m, in \u001B[0;36mcontext_decorator.<locals>.decorate_context\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    112\u001B[0m \u001B[38;5;129m@functools\u001B[39m\u001B[38;5;241m.\u001B[39mwraps(func)\n\u001B[1;32m    113\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mdecorate_context\u001B[39m(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[1;32m    114\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m ctx_factory():\n\u001B[0;32m--> 115\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.conda/envs/nerf-inversion/lib/python3.8/site-packages/nerfstudio/models/base_model.py:195\u001B[0m, in \u001B[0;36mModel.get_outputs_for_camera_ray_bundle\u001B[0;34m(self, camera_ray_bundle)\u001B[0m\n\u001B[1;32m    193\u001B[0m \u001B[38;5;66;03m# move the chunk inputs to the model device\u001B[39;00m\n\u001B[1;32m    194\u001B[0m ray_bundle \u001B[38;5;241m=\u001B[39m ray_bundle\u001B[38;5;241m.\u001B[39mto(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdevice)\n\u001B[0;32m--> 195\u001B[0m outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mforward\u001B[49m\u001B[43m(\u001B[49m\u001B[43mray_bundle\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mray_bundle\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    196\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m output_name, output \u001B[38;5;129;01min\u001B[39;00m outputs\u001B[38;5;241m.\u001B[39mitems():  \u001B[38;5;66;03m# type: ignore\u001B[39;00m\n\u001B[1;32m    197\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(output, torch\u001B[38;5;241m.\u001B[39mTensor):\n\u001B[1;32m    198\u001B[0m         \u001B[38;5;66;03m# TODO: handle lists of tensors as well\u001B[39;00m\n",
      "File \u001B[0;32m~/.conda/envs/nerf-inversion/lib/python3.8/site-packages/nerfstudio/models/base_model.py:143\u001B[0m, in \u001B[0;36mModel.forward\u001B[0;34m(self, ray_bundle)\u001B[0m\n\u001B[1;32m    140\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcollider \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    141\u001B[0m     ray_bundle \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcollider(ray_bundle)\n\u001B[0;32m--> 143\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_outputs\u001B[49m\u001B[43m(\u001B[49m\u001B[43mray_bundle\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.conda/envs/nerf-inversion/lib/python3.8/site-packages/nerfstudio/models/instant_ngp.py:175\u001B[0m, in \u001B[0;36mNGPModel.get_outputs\u001B[0;34m(self, ray_bundle)\u001B[0m\n\u001B[1;32m    172\u001B[0m num_rays \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlen\u001B[39m(ray_bundle)\n\u001B[1;32m    174\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mno_grad():\n\u001B[0;32m--> 175\u001B[0m     ray_samples, ray_indices \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msampler\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    176\u001B[0m \u001B[43m        \u001B[49m\u001B[43mray_bundle\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mray_bundle\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    177\u001B[0m \u001B[43m        \u001B[49m\u001B[43mnear_plane\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconfig\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnear_plane\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    178\u001B[0m \u001B[43m        \u001B[49m\u001B[43mfar_plane\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconfig\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfar_plane\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    179\u001B[0m \u001B[43m        \u001B[49m\u001B[43mrender_step_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconfig\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrender_step_size\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    180\u001B[0m \u001B[43m        \u001B[49m\u001B[43malpha_thre\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconfig\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43malpha_thre\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    181\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcone_angle\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconfig\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcone_angle\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    182\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    184\u001B[0m field_outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfield(ray_samples)\n\u001B[1;32m    185\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconfig\u001B[38;5;241m.\u001B[39muse_gradient_scaling:\n",
      "File \u001B[0;32m~/.conda/envs/nerf-inversion/lib/python3.8/site-packages/torch/nn/modules/module.py:1518\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1516\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1517\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1518\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.conda/envs/nerf-inversion/lib/python3.8/site-packages/torch/nn/modules/module.py:1527\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1522\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1523\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1524\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1525\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1526\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1527\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1529\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1530\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m~/.conda/envs/nerf-inversion/lib/python3.8/site-packages/nerfstudio/model_components/ray_samplers.py:482\u001B[0m, in \u001B[0;36mVolumetricSampler.forward\u001B[0;34m(self, ray_bundle, render_step_size, near_plane, far_plane, alpha_thre, cone_angle)\u001B[0m\n\u001B[1;32m    480\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    481\u001B[0m     camera_indices \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m--> 482\u001B[0m ray_indices, starts, ends \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moccupancy_grid\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msampling\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    483\u001B[0m \u001B[43m    \u001B[49m\u001B[43mrays_o\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrays_o\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    484\u001B[0m \u001B[43m    \u001B[49m\u001B[43mrays_d\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrays_d\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    485\u001B[0m \u001B[43m    \u001B[49m\u001B[43mt_min\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mt_min\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    486\u001B[0m \u001B[43m    \u001B[49m\u001B[43mt_max\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mt_max\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    487\u001B[0m \u001B[43m    \u001B[49m\u001B[43msigma_fn\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_sigma_fn\u001B[49m\u001B[43m(\u001B[49m\u001B[43mrays_o\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mrays_d\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtimes\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    488\u001B[0m \u001B[43m    \u001B[49m\u001B[43mrender_step_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrender_step_size\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    489\u001B[0m \u001B[43m    \u001B[49m\u001B[43mnear_plane\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mnear_plane\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    490\u001B[0m \u001B[43m    \u001B[49m\u001B[43mfar_plane\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfar_plane\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    491\u001B[0m \u001B[43m    \u001B[49m\u001B[43mstratified\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtraining\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    492\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcone_angle\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcone_angle\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    493\u001B[0m \u001B[43m    \u001B[49m\u001B[43malpha_thre\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43malpha_thre\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    494\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    495\u001B[0m num_samples \u001B[38;5;241m=\u001B[39m starts\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m0\u001B[39m]\n\u001B[1;32m    496\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m num_samples \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[1;32m    497\u001B[0m     \u001B[38;5;66;03m# create a single fake sample and update packed_info accordingly\u001B[39;00m\n\u001B[1;32m    498\u001B[0m     \u001B[38;5;66;03m# this says the last ray in packed_info has 1 sample, which starts and ends at 1\u001B[39;00m\n",
      "File \u001B[0;32m~/.conda/envs/nerf-inversion/lib/python3.8/site-packages/torch/utils/_contextlib.py:115\u001B[0m, in \u001B[0;36mcontext_decorator.<locals>.decorate_context\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    112\u001B[0m \u001B[38;5;129m@functools\u001B[39m\u001B[38;5;241m.\u001B[39mwraps(func)\n\u001B[1;32m    113\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mdecorate_context\u001B[39m(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[1;32m    114\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m ctx_factory():\n\u001B[0;32m--> 115\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.conda/envs/nerf-inversion/lib/python3.8/site-packages/nerfacc/estimators/occ_grid.py:187\u001B[0m, in \u001B[0;36mOccGridEstimator.sampling\u001B[0;34m(self, rays_o, rays_d, sigma_fn, alpha_fn, near_plane, far_plane, t_min, t_max, render_step_size, early_stop_eps, alpha_thre, stratified, cone_angle)\u001B[0m\n\u001B[1;32m    185\u001B[0m \u001B[38;5;66;03m# Compute visibility of the samples, and filter out invisible samples\u001B[39;00m\n\u001B[1;32m    186\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m sigma_fn \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m--> 187\u001B[0m     sigmas \u001B[38;5;241m=\u001B[39m \u001B[43msigma_fn\u001B[49m\u001B[43m(\u001B[49m\u001B[43mt_starts\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mt_ends\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mray_indices\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    188\u001B[0m     \u001B[38;5;28;01massert\u001B[39;00m (\n\u001B[1;32m    189\u001B[0m         sigmas\u001B[38;5;241m.\u001B[39mshape \u001B[38;5;241m==\u001B[39m t_starts\u001B[38;5;241m.\u001B[39mshape\n\u001B[1;32m    190\u001B[0m     ), \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msigmas must have shape of (N,)! Got \u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(sigmas\u001B[38;5;241m.\u001B[39mshape)\n\u001B[1;32m    191\u001B[0m     masks \u001B[38;5;241m=\u001B[39m render_visibility_from_density(\n\u001B[1;32m    192\u001B[0m         t_starts\u001B[38;5;241m=\u001B[39mt_starts,\n\u001B[1;32m    193\u001B[0m         t_ends\u001B[38;5;241m=\u001B[39mt_ends,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    197\u001B[0m         alpha_thre\u001B[38;5;241m=\u001B[39malpha_thre,\n\u001B[1;32m    198\u001B[0m     )\n",
      "File \u001B[0;32m~/.conda/envs/nerf-inversion/lib/python3.8/site-packages/nerfstudio/model_components/ray_samplers.py:428\u001B[0m, in \u001B[0;36mVolumetricSampler.get_sigma_fn.<locals>.sigma_fn\u001B[0;34m(t_starts, t_ends, ray_indices)\u001B[0m\n\u001B[1;32m    426\u001B[0m positions \u001B[38;5;241m=\u001B[39m t_origins \u001B[38;5;241m+\u001B[39m t_dirs \u001B[38;5;241m*\u001B[39m (t_starts \u001B[38;5;241m+\u001B[39m t_ends)[:, \u001B[38;5;28;01mNone\u001B[39;00m] \u001B[38;5;241m/\u001B[39m \u001B[38;5;241m2.0\u001B[39m\n\u001B[1;32m    427\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m times \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m--> 428\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mdensity_fn\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpositions\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39msqueeze(\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m)\n\u001B[1;32m    429\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m density_fn(positions, times[ray_indices])\u001B[38;5;241m.\u001B[39msqueeze(\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m)\n",
      "File \u001B[0;32m~/.conda/envs/nerf-inversion/lib/python3.8/site-packages/nerfstudio/fields/base_field.py:67\u001B[0m, in \u001B[0;36mField.density_fn\u001B[0;34m(***failed resolving arguments***)\u001B[0m\n\u001B[1;32m     57\u001B[0m \u001B[38;5;66;03m# Need to figure out a better way to describe positions with a ray.\u001B[39;00m\n\u001B[1;32m     58\u001B[0m ray_samples \u001B[38;5;241m=\u001B[39m RaySamples(\n\u001B[1;32m     59\u001B[0m     frustums\u001B[38;5;241m=\u001B[39mFrustums(\n\u001B[1;32m     60\u001B[0m         origins\u001B[38;5;241m=\u001B[39mpositions,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     65\u001B[0m     )\n\u001B[1;32m     66\u001B[0m )\n\u001B[0;32m---> 67\u001B[0m density, _ \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_density\u001B[49m\u001B[43m(\u001B[49m\u001B[43mray_samples\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     68\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m density\n",
      "File \u001B[0;32m~/.conda/envs/nerf-inversion/lib/python3.8/site-packages/nerfstudio/fields/nerfacto_field.py:219\u001B[0m, in \u001B[0;36mNerfactoField.get_density\u001B[0;34m(self, ray_samples)\u001B[0m\n\u001B[1;32m    217\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_sample_locations\u001B[38;5;241m.\u001B[39mrequires_grad \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[1;32m    218\u001B[0m positions_flat \u001B[38;5;241m=\u001B[39m positions\u001B[38;5;241m.\u001B[39mview(\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m3\u001B[39m)\n\u001B[0;32m--> 219\u001B[0m h \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmlp_base\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpositions_flat\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mview\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mray_samples\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfrustums\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mshape\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m-\u001B[39;49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m    220\u001B[0m density_before_activation, base_mlp_out \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39msplit(h, [\u001B[38;5;241m1\u001B[39m, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgeo_feat_dim], dim\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m)\n\u001B[1;32m    221\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_density_before_activation \u001B[38;5;241m=\u001B[39m density_before_activation\n",
      "\u001B[0;31mRuntimeError\u001B[0m: cannot reshape tensor of 0 elements into shape [0, -1] because the unspecified dimension size -1 can be any value and is ambiguous"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-23T22:49:23.806808Z",
     "start_time": "2024-08-23T22:49:23.617201Z"
    }
   },
   "cell_type": "code",
   "source": [
    "outputs = nerf_model.get_outputs_for_camera(camera)\n",
    "generated_rgb = outputs[\"rgb\"]"
   ],
   "id": "b9427e2d79b2cf72",
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: invalid configuration argument\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[22], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m outputs \u001B[38;5;241m=\u001B[39m \u001B[43mnerf_model\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_outputs_for_camera\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcamera\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      2\u001B[0m generated_rgb \u001B[38;5;241m=\u001B[39m outputs[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mrgb\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n",
      "File \u001B[0;32m~/.conda/envs/nerf-inversion/lib/python3.8/site-packages/torch/utils/_contextlib.py:115\u001B[0m, in \u001B[0;36mcontext_decorator.<locals>.decorate_context\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    112\u001B[0m \u001B[38;5;129m@functools\u001B[39m\u001B[38;5;241m.\u001B[39mwraps(func)\n\u001B[1;32m    113\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mdecorate_context\u001B[39m(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[1;32m    114\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m ctx_factory():\n\u001B[0;32m--> 115\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.conda/envs/nerf-inversion/lib/python3.8/site-packages/nerfstudio/models/base_model.py:173\u001B[0m, in \u001B[0;36mModel.get_outputs_for_camera\u001B[0;34m(self, camera, obb_box)\u001B[0m\n\u001B[1;32m    165\u001B[0m \u001B[38;5;129m@torch\u001B[39m\u001B[38;5;241m.\u001B[39mno_grad()\n\u001B[1;32m    166\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mget_outputs_for_camera\u001B[39m(\u001B[38;5;28mself\u001B[39m, camera: Cameras, obb_box: Optional[OrientedBox] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Dict[\u001B[38;5;28mstr\u001B[39m, torch\u001B[38;5;241m.\u001B[39mTensor]:\n\u001B[1;32m    167\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Takes in a camera, generates the raybundle, and computes the output of the model.\u001B[39;00m\n\u001B[1;32m    168\u001B[0m \u001B[38;5;124;03m    Assumes a ray-based model.\u001B[39;00m\n\u001B[1;32m    169\u001B[0m \n\u001B[1;32m    170\u001B[0m \u001B[38;5;124;03m    Args:\u001B[39;00m\n\u001B[1;32m    171\u001B[0m \u001B[38;5;124;03m        camera: generates raybundle\u001B[39;00m\n\u001B[1;32m    172\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m--> 173\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_outputs_for_camera_ray_bundle\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    174\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcamera\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgenerate_rays\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcamera_indices\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkeep_shape\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mobb_box\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mobb_box\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    175\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.conda/envs/nerf-inversion/lib/python3.8/site-packages/torch/utils/_contextlib.py:115\u001B[0m, in \u001B[0;36mcontext_decorator.<locals>.decorate_context\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    112\u001B[0m \u001B[38;5;129m@functools\u001B[39m\u001B[38;5;241m.\u001B[39mwraps(func)\n\u001B[1;32m    113\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mdecorate_context\u001B[39m(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[1;32m    114\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m ctx_factory():\n\u001B[0;32m--> 115\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.conda/envs/nerf-inversion/lib/python3.8/site-packages/nerfstudio/models/base_model.py:195\u001B[0m, in \u001B[0;36mModel.get_outputs_for_camera_ray_bundle\u001B[0;34m(self, camera_ray_bundle)\u001B[0m\n\u001B[1;32m    193\u001B[0m \u001B[38;5;66;03m# move the chunk inputs to the model device\u001B[39;00m\n\u001B[1;32m    194\u001B[0m ray_bundle \u001B[38;5;241m=\u001B[39m ray_bundle\u001B[38;5;241m.\u001B[39mto(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdevice)\n\u001B[0;32m--> 195\u001B[0m outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mforward\u001B[49m\u001B[43m(\u001B[49m\u001B[43mray_bundle\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mray_bundle\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    196\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m output_name, output \u001B[38;5;129;01min\u001B[39;00m outputs\u001B[38;5;241m.\u001B[39mitems():  \u001B[38;5;66;03m# type: ignore\u001B[39;00m\n\u001B[1;32m    197\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(output, torch\u001B[38;5;241m.\u001B[39mTensor):\n\u001B[1;32m    198\u001B[0m         \u001B[38;5;66;03m# TODO: handle lists of tensors as well\u001B[39;00m\n",
      "File \u001B[0;32m~/.conda/envs/nerf-inversion/lib/python3.8/site-packages/nerfstudio/models/base_model.py:143\u001B[0m, in \u001B[0;36mModel.forward\u001B[0;34m(self, ray_bundle)\u001B[0m\n\u001B[1;32m    140\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcollider \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    141\u001B[0m     ray_bundle \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcollider(ray_bundle)\n\u001B[0;32m--> 143\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_outputs\u001B[49m\u001B[43m(\u001B[49m\u001B[43mray_bundle\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.conda/envs/nerf-inversion/lib/python3.8/site-packages/nerfstudio/models/instant_ngp.py:175\u001B[0m, in \u001B[0;36mNGPModel.get_outputs\u001B[0;34m(self, ray_bundle)\u001B[0m\n\u001B[1;32m    172\u001B[0m num_rays \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlen\u001B[39m(ray_bundle)\n\u001B[1;32m    174\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mno_grad():\n\u001B[0;32m--> 175\u001B[0m     ray_samples, ray_indices \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msampler\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    176\u001B[0m \u001B[43m        \u001B[49m\u001B[43mray_bundle\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mray_bundle\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    177\u001B[0m \u001B[43m        \u001B[49m\u001B[43mnear_plane\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconfig\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnear_plane\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    178\u001B[0m \u001B[43m        \u001B[49m\u001B[43mfar_plane\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconfig\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfar_plane\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    179\u001B[0m \u001B[43m        \u001B[49m\u001B[43mrender_step_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconfig\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrender_step_size\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    180\u001B[0m \u001B[43m        \u001B[49m\u001B[43malpha_thre\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconfig\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43malpha_thre\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    181\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcone_angle\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconfig\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcone_angle\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    182\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    184\u001B[0m field_outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfield(ray_samples)\n\u001B[1;32m    185\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconfig\u001B[38;5;241m.\u001B[39muse_gradient_scaling:\n",
      "File \u001B[0;32m~/.conda/envs/nerf-inversion/lib/python3.8/site-packages/torch/nn/modules/module.py:1518\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1516\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1517\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1518\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.conda/envs/nerf-inversion/lib/python3.8/site-packages/torch/nn/modules/module.py:1527\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1522\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1523\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1524\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1525\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1526\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1527\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1529\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1530\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m~/.conda/envs/nerf-inversion/lib/python3.8/site-packages/nerfstudio/model_components/ray_samplers.py:482\u001B[0m, in \u001B[0;36mVolumetricSampler.forward\u001B[0;34m(self, ray_bundle, render_step_size, near_plane, far_plane, alpha_thre, cone_angle)\u001B[0m\n\u001B[1;32m    480\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    481\u001B[0m     camera_indices \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m--> 482\u001B[0m ray_indices, starts, ends \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moccupancy_grid\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msampling\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    483\u001B[0m \u001B[43m    \u001B[49m\u001B[43mrays_o\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrays_o\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    484\u001B[0m \u001B[43m    \u001B[49m\u001B[43mrays_d\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrays_d\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    485\u001B[0m \u001B[43m    \u001B[49m\u001B[43mt_min\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mt_min\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    486\u001B[0m \u001B[43m    \u001B[49m\u001B[43mt_max\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mt_max\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    487\u001B[0m \u001B[43m    \u001B[49m\u001B[43msigma_fn\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_sigma_fn\u001B[49m\u001B[43m(\u001B[49m\u001B[43mrays_o\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mrays_d\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtimes\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    488\u001B[0m \u001B[43m    \u001B[49m\u001B[43mrender_step_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrender_step_size\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    489\u001B[0m \u001B[43m    \u001B[49m\u001B[43mnear_plane\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mnear_plane\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    490\u001B[0m \u001B[43m    \u001B[49m\u001B[43mfar_plane\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfar_plane\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    491\u001B[0m \u001B[43m    \u001B[49m\u001B[43mstratified\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtraining\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    492\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcone_angle\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcone_angle\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    493\u001B[0m \u001B[43m    \u001B[49m\u001B[43malpha_thre\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43malpha_thre\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    494\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    495\u001B[0m num_samples \u001B[38;5;241m=\u001B[39m starts\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m0\u001B[39m]\n\u001B[1;32m    496\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m num_samples \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[1;32m    497\u001B[0m     \u001B[38;5;66;03m# create a single fake sample and update packed_info accordingly\u001B[39;00m\n\u001B[1;32m    498\u001B[0m     \u001B[38;5;66;03m# this says the last ray in packed_info has 1 sample, which starts and ends at 1\u001B[39;00m\n",
      "File \u001B[0;32m~/.conda/envs/nerf-inversion/lib/python3.8/site-packages/torch/utils/_contextlib.py:115\u001B[0m, in \u001B[0;36mcontext_decorator.<locals>.decorate_context\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    112\u001B[0m \u001B[38;5;129m@functools\u001B[39m\u001B[38;5;241m.\u001B[39mwraps(func)\n\u001B[1;32m    113\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mdecorate_context\u001B[39m(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[1;32m    114\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m ctx_factory():\n\u001B[0;32m--> 115\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.conda/envs/nerf-inversion/lib/python3.8/site-packages/nerfacc/estimators/occ_grid.py:154\u001B[0m, in \u001B[0;36mOccGridEstimator.sampling\u001B[0;34m(self, rays_o, rays_d, sigma_fn, alpha_fn, near_plane, far_plane, t_min, t_max, render_step_size, early_stop_eps, alpha_thre, stratified, cone_angle)\u001B[0m\n\u001B[1;32m     85\u001B[0m \u001B[38;5;129m@torch\u001B[39m\u001B[38;5;241m.\u001B[39mno_grad()\n\u001B[1;32m     86\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21msampling\u001B[39m(\n\u001B[1;32m     87\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    103\u001B[0m     cone_angle: \u001B[38;5;28mfloat\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0.0\u001B[39m,\n\u001B[1;32m    104\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tuple[Tensor, Tensor, Tensor]:\n\u001B[1;32m    105\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Sampling with spatial skipping.\u001B[39;00m\n\u001B[1;32m    106\u001B[0m \n\u001B[1;32m    107\u001B[0m \u001B[38;5;124;03m    Note:\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    151\u001B[0m \n\u001B[1;32m    152\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m--> 154\u001B[0m     near_planes \u001B[38;5;241m=\u001B[39m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfull_like\u001B[49m\u001B[43m(\u001B[49m\u001B[43mrays_o\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfill_value\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mnear_plane\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    155\u001B[0m     far_planes \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mfull_like(rays_o[\u001B[38;5;241m.\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;241m.\u001B[39m, \u001B[38;5;241m0\u001B[39m], fill_value\u001B[38;5;241m=\u001B[39mfar_plane)\n\u001B[1;32m    157\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m t_min \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "\u001B[0;31mRuntimeError\u001B[0m: CUDA error: invalid configuration argument\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "7f2bef569f90699c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "f9ceea09ee9a93b7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "58d9dfc72902757"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-23T21:25:22.258173Z",
     "start_time": "2024-08-23T21:25:22.238881Z"
    }
   },
   "cell_type": "code",
   "source": "optimizer = torch.optim.Adam([final_matrix], lr=0.001)",
   "id": "5a269783ad42b8dd",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-23T21:25:24.787208Z",
     "start_time": "2024-08-23T21:25:24.725259Z"
    }
   },
   "cell_type": "code",
   "source": [
    "target_image = image_to_tensor(\"/n/home10/dpodolskyi/neural-registration/data/datasets/0_065_cat5_2.0/images/4.png\", device=nerf_model.device)\n",
    "\n",
    "target_image.shape, target_image.requires_grad"
   ],
   "id": "1e37f41096bb42d0",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([512, 512, 3]), False)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-23T21:25:27.589110Z",
     "start_time": "2024-08-23T21:25:27.587249Z"
    }
   },
   "cell_type": "code",
   "source": "mse_loss = nn.MSELoss()",
   "id": "7f7effac994be83f",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-23T21:25:29.368714Z",
     "start_time": "2024-08-23T21:25:29.260752Z"
    }
   },
   "cell_type": "code",
   "source": "render_rays = camera.generate_rays(camera_indices=0, keep_shape=True)",
   "id": "a622bbeb38394857",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "62122e794ec97d06"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-23T21:25:31.856956Z",
     "start_time": "2024-08-23T21:25:30.052597Z"
    }
   },
   "cell_type": "code",
   "source": "rendered_image = nerf_model.get_outputs_for_camera_ray_bundle(render_rays)",
   "id": "c967fc6ac6f88e47",
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "cannot reshape tensor of 0 elements into shape [0, -1] because the unspecified dimension size -1 can be any value and is ambiguous",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[12], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m rendered_image \u001B[38;5;241m=\u001B[39m \u001B[43mnerf_model\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_outputs_for_camera_ray_bundle\u001B[49m\u001B[43m(\u001B[49m\u001B[43mrender_rays\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.conda/envs/nerf-inversion/lib/python3.8/site-packages/torch/utils/_contextlib.py:115\u001B[0m, in \u001B[0;36mcontext_decorator.<locals>.decorate_context\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    112\u001B[0m \u001B[38;5;129m@functools\u001B[39m\u001B[38;5;241m.\u001B[39mwraps(func)\n\u001B[1;32m    113\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mdecorate_context\u001B[39m(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[1;32m    114\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m ctx_factory():\n\u001B[0;32m--> 115\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.conda/envs/nerf-inversion/lib/python3.8/site-packages/nerfstudio/models/base_model.py:195\u001B[0m, in \u001B[0;36mModel.get_outputs_for_camera_ray_bundle\u001B[0;34m(self, camera_ray_bundle)\u001B[0m\n\u001B[1;32m    193\u001B[0m \u001B[38;5;66;03m# move the chunk inputs to the model device\u001B[39;00m\n\u001B[1;32m    194\u001B[0m ray_bundle \u001B[38;5;241m=\u001B[39m ray_bundle\u001B[38;5;241m.\u001B[39mto(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdevice)\n\u001B[0;32m--> 195\u001B[0m outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mforward\u001B[49m\u001B[43m(\u001B[49m\u001B[43mray_bundle\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mray_bundle\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    196\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m output_name, output \u001B[38;5;129;01min\u001B[39;00m outputs\u001B[38;5;241m.\u001B[39mitems():  \u001B[38;5;66;03m# type: ignore\u001B[39;00m\n\u001B[1;32m    197\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(output, torch\u001B[38;5;241m.\u001B[39mTensor):\n\u001B[1;32m    198\u001B[0m         \u001B[38;5;66;03m# TODO: handle lists of tensors as well\u001B[39;00m\n",
      "File \u001B[0;32m~/.conda/envs/nerf-inversion/lib/python3.8/site-packages/nerfstudio/models/base_model.py:143\u001B[0m, in \u001B[0;36mModel.forward\u001B[0;34m(self, ray_bundle)\u001B[0m\n\u001B[1;32m    140\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcollider \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    141\u001B[0m     ray_bundle \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcollider(ray_bundle)\n\u001B[0;32m--> 143\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_outputs\u001B[49m\u001B[43m(\u001B[49m\u001B[43mray_bundle\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.conda/envs/nerf-inversion/lib/python3.8/site-packages/nerfstudio/models/instant_ngp.py:175\u001B[0m, in \u001B[0;36mNGPModel.get_outputs\u001B[0;34m(self, ray_bundle)\u001B[0m\n\u001B[1;32m    172\u001B[0m num_rays \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlen\u001B[39m(ray_bundle)\n\u001B[1;32m    174\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mno_grad():\n\u001B[0;32m--> 175\u001B[0m     ray_samples, ray_indices \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msampler\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    176\u001B[0m \u001B[43m        \u001B[49m\u001B[43mray_bundle\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mray_bundle\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    177\u001B[0m \u001B[43m        \u001B[49m\u001B[43mnear_plane\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconfig\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnear_plane\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    178\u001B[0m \u001B[43m        \u001B[49m\u001B[43mfar_plane\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconfig\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfar_plane\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    179\u001B[0m \u001B[43m        \u001B[49m\u001B[43mrender_step_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconfig\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrender_step_size\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    180\u001B[0m \u001B[43m        \u001B[49m\u001B[43malpha_thre\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconfig\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43malpha_thre\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    181\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcone_angle\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconfig\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcone_angle\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    182\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    184\u001B[0m field_outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfield(ray_samples)\n\u001B[1;32m    185\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconfig\u001B[38;5;241m.\u001B[39muse_gradient_scaling:\n",
      "File \u001B[0;32m~/.conda/envs/nerf-inversion/lib/python3.8/site-packages/torch/nn/modules/module.py:1518\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1516\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1517\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1518\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.conda/envs/nerf-inversion/lib/python3.8/site-packages/torch/nn/modules/module.py:1527\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1522\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1523\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1524\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1525\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1526\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1527\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1529\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1530\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m~/.conda/envs/nerf-inversion/lib/python3.8/site-packages/nerfstudio/model_components/ray_samplers.py:482\u001B[0m, in \u001B[0;36mVolumetricSampler.forward\u001B[0;34m(self, ray_bundle, render_step_size, near_plane, far_plane, alpha_thre, cone_angle)\u001B[0m\n\u001B[1;32m    480\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    481\u001B[0m     camera_indices \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m--> 482\u001B[0m ray_indices, starts, ends \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moccupancy_grid\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msampling\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    483\u001B[0m \u001B[43m    \u001B[49m\u001B[43mrays_o\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrays_o\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    484\u001B[0m \u001B[43m    \u001B[49m\u001B[43mrays_d\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrays_d\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    485\u001B[0m \u001B[43m    \u001B[49m\u001B[43mt_min\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mt_min\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    486\u001B[0m \u001B[43m    \u001B[49m\u001B[43mt_max\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mt_max\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    487\u001B[0m \u001B[43m    \u001B[49m\u001B[43msigma_fn\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_sigma_fn\u001B[49m\u001B[43m(\u001B[49m\u001B[43mrays_o\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mrays_d\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtimes\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    488\u001B[0m \u001B[43m    \u001B[49m\u001B[43mrender_step_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrender_step_size\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    489\u001B[0m \u001B[43m    \u001B[49m\u001B[43mnear_plane\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mnear_plane\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    490\u001B[0m \u001B[43m    \u001B[49m\u001B[43mfar_plane\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfar_plane\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    491\u001B[0m \u001B[43m    \u001B[49m\u001B[43mstratified\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtraining\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    492\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcone_angle\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcone_angle\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    493\u001B[0m \u001B[43m    \u001B[49m\u001B[43malpha_thre\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43malpha_thre\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    494\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    495\u001B[0m num_samples \u001B[38;5;241m=\u001B[39m starts\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m0\u001B[39m]\n\u001B[1;32m    496\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m num_samples \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[1;32m    497\u001B[0m     \u001B[38;5;66;03m# create a single fake sample and update packed_info accordingly\u001B[39;00m\n\u001B[1;32m    498\u001B[0m     \u001B[38;5;66;03m# this says the last ray in packed_info has 1 sample, which starts and ends at 1\u001B[39;00m\n",
      "File \u001B[0;32m~/.conda/envs/nerf-inversion/lib/python3.8/site-packages/torch/utils/_contextlib.py:115\u001B[0m, in \u001B[0;36mcontext_decorator.<locals>.decorate_context\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    112\u001B[0m \u001B[38;5;129m@functools\u001B[39m\u001B[38;5;241m.\u001B[39mwraps(func)\n\u001B[1;32m    113\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mdecorate_context\u001B[39m(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[1;32m    114\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m ctx_factory():\n\u001B[0;32m--> 115\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.conda/envs/nerf-inversion/lib/python3.8/site-packages/nerfacc/estimators/occ_grid.py:187\u001B[0m, in \u001B[0;36mOccGridEstimator.sampling\u001B[0;34m(self, rays_o, rays_d, sigma_fn, alpha_fn, near_plane, far_plane, t_min, t_max, render_step_size, early_stop_eps, alpha_thre, stratified, cone_angle)\u001B[0m\n\u001B[1;32m    185\u001B[0m \u001B[38;5;66;03m# Compute visibility of the samples, and filter out invisible samples\u001B[39;00m\n\u001B[1;32m    186\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m sigma_fn \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m--> 187\u001B[0m     sigmas \u001B[38;5;241m=\u001B[39m \u001B[43msigma_fn\u001B[49m\u001B[43m(\u001B[49m\u001B[43mt_starts\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mt_ends\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mray_indices\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    188\u001B[0m     \u001B[38;5;28;01massert\u001B[39;00m (\n\u001B[1;32m    189\u001B[0m         sigmas\u001B[38;5;241m.\u001B[39mshape \u001B[38;5;241m==\u001B[39m t_starts\u001B[38;5;241m.\u001B[39mshape\n\u001B[1;32m    190\u001B[0m     ), \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msigmas must have shape of (N,)! Got \u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(sigmas\u001B[38;5;241m.\u001B[39mshape)\n\u001B[1;32m    191\u001B[0m     masks \u001B[38;5;241m=\u001B[39m render_visibility_from_density(\n\u001B[1;32m    192\u001B[0m         t_starts\u001B[38;5;241m=\u001B[39mt_starts,\n\u001B[1;32m    193\u001B[0m         t_ends\u001B[38;5;241m=\u001B[39mt_ends,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    197\u001B[0m         alpha_thre\u001B[38;5;241m=\u001B[39malpha_thre,\n\u001B[1;32m    198\u001B[0m     )\n",
      "File \u001B[0;32m~/.conda/envs/nerf-inversion/lib/python3.8/site-packages/nerfstudio/model_components/ray_samplers.py:428\u001B[0m, in \u001B[0;36mVolumetricSampler.get_sigma_fn.<locals>.sigma_fn\u001B[0;34m(t_starts, t_ends, ray_indices)\u001B[0m\n\u001B[1;32m    426\u001B[0m positions \u001B[38;5;241m=\u001B[39m t_origins \u001B[38;5;241m+\u001B[39m t_dirs \u001B[38;5;241m*\u001B[39m (t_starts \u001B[38;5;241m+\u001B[39m t_ends)[:, \u001B[38;5;28;01mNone\u001B[39;00m] \u001B[38;5;241m/\u001B[39m \u001B[38;5;241m2.0\u001B[39m\n\u001B[1;32m    427\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m times \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m--> 428\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mdensity_fn\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpositions\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39msqueeze(\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m)\n\u001B[1;32m    429\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m density_fn(positions, times[ray_indices])\u001B[38;5;241m.\u001B[39msqueeze(\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m)\n",
      "File \u001B[0;32m~/.conda/envs/nerf-inversion/lib/python3.8/site-packages/nerfstudio/fields/base_field.py:67\u001B[0m, in \u001B[0;36mField.density_fn\u001B[0;34m(***failed resolving arguments***)\u001B[0m\n\u001B[1;32m     57\u001B[0m \u001B[38;5;66;03m# Need to figure out a better way to describe positions with a ray.\u001B[39;00m\n\u001B[1;32m     58\u001B[0m ray_samples \u001B[38;5;241m=\u001B[39m RaySamples(\n\u001B[1;32m     59\u001B[0m     frustums\u001B[38;5;241m=\u001B[39mFrustums(\n\u001B[1;32m     60\u001B[0m         origins\u001B[38;5;241m=\u001B[39mpositions,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     65\u001B[0m     )\n\u001B[1;32m     66\u001B[0m )\n\u001B[0;32m---> 67\u001B[0m density, _ \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_density\u001B[49m\u001B[43m(\u001B[49m\u001B[43mray_samples\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     68\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m density\n",
      "File \u001B[0;32m~/.conda/envs/nerf-inversion/lib/python3.8/site-packages/nerfstudio/fields/nerfacto_field.py:219\u001B[0m, in \u001B[0;36mNerfactoField.get_density\u001B[0;34m(self, ray_samples)\u001B[0m\n\u001B[1;32m    217\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_sample_locations\u001B[38;5;241m.\u001B[39mrequires_grad \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[1;32m    218\u001B[0m positions_flat \u001B[38;5;241m=\u001B[39m positions\u001B[38;5;241m.\u001B[39mview(\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m3\u001B[39m)\n\u001B[0;32m--> 219\u001B[0m h \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmlp_base\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpositions_flat\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mview\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mray_samples\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfrustums\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mshape\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m-\u001B[39;49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m    220\u001B[0m density_before_activation, base_mlp_out \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39msplit(h, [\u001B[38;5;241m1\u001B[39m, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgeo_feat_dim], dim\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m)\n\u001B[1;32m    221\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_density_before_activation \u001B[38;5;241m=\u001B[39m density_before_activation\n",
      "\u001B[0;31mRuntimeError\u001B[0m: cannot reshape tensor of 0 elements into shape [0, -1] because the unspecified dimension size -1 can be any value and is ambiguous"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "3258ddd0e8331268",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "c0a2876217eddfe1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "3f32578e10462a67",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "3849defac769af76",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "6bb96de1548eb838",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "5b098602a735d82a",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
