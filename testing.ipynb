{
 "cells": [
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": "!ml load cuda/11.8.0-fasrc01",
   "id": "50dab1064dbf144a",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-08-01T22:44:12.934647Z",
     "start_time": "2024-08-01T22:44:12.932096Z"
    }
   },
   "source": [
    "import torch\n",
    "from pathlib import Path\n",
    "from nerfstudio.cameras.cameras import Cameras, CameraType\n",
    "from nerfstudio.utils.eval_utils import eval_setup\n",
    "from nerfstudio.cameras.rays import RayBundle\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n"
   ],
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "5181cb2ebe659070",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Class implementation",
   "id": "3508c4e88231f0ce"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-01T22:43:40.459441Z",
     "start_time": "2024-08-01T22:43:37.377581Z"
    }
   },
   "cell_type": "code",
   "source": [
    "config_path = \"/n/home10/dpodolskyi/neural-registration/outputs/0_065_cat5_2/nerfacto/2024-08-01_153850/config.yml\"\n",
    "_, pipeline, _, _ = eval_setup(config_path=Path(config_path), test_mode=\"inference\")\n",
    "nerf_model = pipeline.model\n",
    "device = pipeline.device"
   ],
   "id": "5df73c6d98e1ea2e",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Loading latest checkpoint from load_dir\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Loading latest checkpoint from load_dir\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "✅ Done loading checkpoint from outputs/0_065_cat5_2/nerfacto/\u001B[1;36m2024\u001B[0m-\u001B[1;36m08\u001B[0m-01_153850/nerfstudio_models/step-\u001B[1;36m000029999.\u001B[0mckpt\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">✅ Done loading checkpoint from outputs/0_065_cat5_2/nerfacto/<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2024</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">08</span>-01_153850/nerfstudio_models/step-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">000029999.</span>ckpt\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-01T22:43:58.678681Z",
     "start_time": "2024-08-01T22:43:58.672147Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def calculate_camera_to_world_matrix(eye: torch.Tensor, target: torch.Tensor, up: torch.Tensor) -> torch.Tensor:\n",
    "    forward = (eye - target) / torch.norm(target - eye)\n",
    "    right = torch.cross((up - eye), forward)\n",
    "    right /= torch.norm(right)\n",
    "    up = torch.cross(forward, right)\n",
    "    rotation_matrices = torch.stack([right, up, forward], dim=-1)\n",
    "    camera_to_world_matrices = torch.eye(4, device=eye.device)\n",
    "    camera_to_world_matrices[:3, :3] = rotation_matrices\n",
    "    camera_to_world_matrices[:3, 3] = eye\n",
    "    return camera_to_world_matrices[:3, :].unsqueeze(0)\n",
    "\n",
    "def rotation_matrix_y(angles: torch.Tensor) -> torch.Tensor:\n",
    "    cos_angles = torch.cos(angles)\n",
    "    sin_angles = torch.sin(angles)\n",
    "    rotation_matrices = torch.zeros((angles.shape[0], 3, 3), device=angles.device)\n",
    "    rotation_matrices[:, 0, 0] = cos_angles\n",
    "    rotation_matrices[:, 0, 2] = sin_angles\n",
    "    rotation_matrices[:, 1, 1] = 1\n",
    "    rotation_matrices[:, 2, 0] = -sin_angles\n",
    "    rotation_matrices[:, 2, 2] = cos_angles\n",
    "    return rotation_matrices\n",
    "\n",
    "def rotate_camera_to_world_matrices(camera_to_worlds: torch.Tensor, start_angle: float, end_angle: float, intermediate_steps: int) -> torch.Tensor:\n",
    "    device = camera_to_worlds.device\n",
    "    start_angle = np.deg2rad(start_angle)\n",
    "    end_angle = np.deg2rad(end_angle)\n",
    "    angles = torch.linspace(start_angle, end_angle, intermediate_steps, device=device)\n",
    "    rotation_matrices = rotation_matrix_y(angles).transpose(1, 2)\n",
    "    \n",
    "    num_cameras = camera_to_worlds.shape[0]\n",
    "    num_rotations = rotation_matrices.shape[0]\n",
    "    \n",
    "    expanded_camera_matrices = camera_to_worlds.unsqueeze(1).repeat(1, num_rotations, 1, 1)\n",
    "    expanded_rotation_matrices = rotation_matrices.unsqueeze(0).repeat(num_cameras, 1, 1, 1)\n",
    "    \n",
    "    rotated_matrices = torch.matmul(expanded_camera_matrices[..., :3], expanded_rotation_matrices)\n",
    "    result_matrices = torch.cat((rotated_matrices, expanded_camera_matrices[..., 3:]), dim=-1)\n",
    "    \n",
    "    return result_matrices.view(-1, 3, 4)"
   ],
   "id": "126c5a1bf99352cd",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-01T22:43:59.961830Z",
     "start_time": "2024-08-01T22:43:59.959433Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Step 3: Define camera parameters\n",
    "camera_params = {\n",
    "    \"camera_angle_x\": 0.5235987755982988,\n",
    "    \"camera_angle_y\": 0.5235987755982988,\n",
    "    \"fl_x\": 955.4050067376327,\n",
    "    \"fl_y\": 955.4050067376327,\n",
    "    \"cx\": 256.0,\n",
    "    \"cy\": 256.0,\n",
    "    \"w\": 512,\n",
    "    \"h\": 512,\n",
    "}"
   ],
   "id": "af2adc2007e78430",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-01T22:44:00.698199Z",
     "start_time": "2024-08-01T22:44:00.690858Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def create_camera(camera_params, transform_matrix, device):\n",
    "    fx, fy = camera_params['fl_x'], camera_params['fl_y']\n",
    "    cx, cy = camera_params['cx'], camera_params['cy']\n",
    "    width, height = camera_params['w'], camera_params['h']\n",
    "\n",
    "    camera = Cameras(\n",
    "        fx=torch.tensor([fx], device=device),\n",
    "        fy=torch.tensor([fy], device=device),\n",
    "        cx=torch.tensor([cx], device=device),\n",
    "        cy=torch.tensor([cy], device=device),\n",
    "        camera_to_worlds=transform_matrix,\n",
    "        width=torch.tensor([width], device=device),\n",
    "        height=torch.tensor([height], device=device),\n",
    "        camera_type=CameraType.PERSPECTIVE\n",
    "    )\n",
    "    return camera\n",
    "\n",
    "def render_image(model, camera):\n",
    "    with torch.no_grad():\n",
    "        outputs = model.get_outputs_for_camera(camera)\n",
    "    return outputs['rgb']\n",
    "\n",
    "def post_process_and_save(rgb_image, output_path):\n",
    "    rgb_image = rgb_image.cpu().numpy()\n",
    "    rgb_image = (rgb_image * 255).astype('uint8')\n",
    "    plt.imshow(rgb_image)\n",
    "    plt.axis('off')\n",
    "    plt.savefig(output_path, bbox_inches='tight', pad_inches=0)\n",
    "    plt.close()\n",
    "\n",
    "def generate_rgb_image(camera_params, transform_matrix, device, model, output_path, start_angle, end_angle, intermediate_steps):\n",
    "    eye = torch.tensor([-80.73672706466026, 15.51473463480075, 12.348141976499424], device=device)\n",
    "    target = torch.tensor([0.0, 0.0, 0.0], device=device)\n",
    "    up = torch.tensor([0.0, -1.0, 0.0], device=device)\n",
    "    \n",
    "    camera_to_world = calculate_camera_to_world_matrix(eye, target, up)\n",
    "    rotated_matrices = rotate_camera_to_world_matrices(camera_to_world, start_angle, end_angle, intermediate_steps)\n",
    "    \n",
    "    camera = create_camera(camera_params, rotated_matrices, device)\n",
    "    rgb_image = render_image(model, camera)\n",
    "    \n",
    "    post_process_and_save(rgb_image, output_path)"
   ],
   "id": "7b3ee8bbf1f3c6c2",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-01T22:44:01.811289Z",
     "start_time": "2024-08-01T22:44:01.809601Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "b571f79ef9b48af7",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-01T22:44:17.202987Z",
     "start_time": "2024-08-01T22:44:15.485889Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Example usage\n",
    "transform_matrix = torch.tensor([\n",
    "    [-0.16551750084030392, 0.17173068552312126, -0.9711398089695112, -80.73672706466026],\n",
    "    [-0.9756847655052445, 0.11494663876681419, 0.18661861803471735, 15.51473463480075],\n",
    "    [0.14367740002017088, 0.9784149640546033, 0.14852933325600515, 12.348141976499424],\n",
    "    [0.0, 0.0, 0.0, 1.0]\n",
    "], device=device)\n",
    "\n",
    "output_path = \"output_rgb_image.png\"\n",
    "start_angle = 0.0\n",
    "end_angle = 345.0\n",
    "intermediate_steps = 20\n",
    "\n",
    "generate_rgb_image(camera_params, transform_matrix, device, nerf_model, output_path, start_angle, end_angle, intermediate_steps)\n",
    "print(f\"RGB image saved to {output_path}\")"
   ],
   "id": "c6f6f8e6aa8344c0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RGB image saved to output_rgb_image.png\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-01T22:44:26.373453Z",
     "start_time": "2024-08-01T22:44:26.225817Z"
    }
   },
   "cell_type": "code",
   "source": "!ls",
   "id": "8935a546cc331900",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data\tmain.py\t\toutput_rgb_image.png  README.md\r\n",
      "losses\tnerf_inversion\toutputs\t\t      testing.ipynb\r\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "5deb0dd1cff84e15",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
