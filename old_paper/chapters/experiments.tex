\chapter{Experiments}

This chapter describes the experimental setup used to evaluate our NeRF-based intraoperative registration framework. We detail the datasets, evaluation metrics, and experimental protocols used to assess the performance of different loss functions and hypernetwork approaches.

\section{Experimental Objectives}
Our experiments are designed to address the following research questions:

\begin{enumerate}
    \item How do different loss functions affect the accuracy and robustness of NeRF-based registration?
    \item How effective are hypernetwork-based style transfer approaches for cross-modal registration?
    \item How does the initial pose estimate affect the convergence and accuracy of the registration?
    \item What are the computational requirements and runtime performance of the proposed methods?
\end{enumerate}

\section{Datasets}
We use both synthetic and real datasets to evaluate our framework:

\subsection{Synthetic Dataset}
To enable controlled experiments with ground truth, we generate a synthetic dataset using a pre-trained NeRF model of a brain surface. The dataset consists of:

\begin{itemize}
    \item 100 target images rendered from random camera poses
    \item For each target image, 5 initial poses with varying degrees of perturbation from the ground truth pose
    \item Perturbations ranging from small (1-5 degrees rotation, 1-5 mm translation) to large (10-30 degrees rotation, 10-30 mm translation)
\end{itemize}

This synthetic dataset allows us to evaluate the registration accuracy with known ground truth poses and controlled perturbations.

\subsection{Real Dataset}
For real-world evaluation, we use a dataset of intraoperative brain images collected during neurosurgical procedures:

\begin{itemize}
    \item 20 cases with preoperative MRI scans
    \item Intraoperative optical images of the exposed brain surface
    \item Manually annotated correspondences between the preoperative and intraoperative images for evaluation
\end{itemize}

For each case, we train a NeRF model on the preoperative MRI data and use our framework to register it with the intraoperative images.

\section{Evaluation Metrics}
We use the following metrics to evaluate the registration performance:

\subsection{Pose Error Metrics}
For the synthetic dataset with known ground truth poses, we compute:

\begin{itemize}
    \item \textbf{Translation Error}: The Euclidean distance between the estimated and ground truth translation vectors, measured in millimeters.
    \item \textbf{Rotation Error}: The angular difference between the estimated and ground truth rotation matrices, measured in degrees.
    \item \textbf{Combined Pose Error}: A weighted combination of translation and rotation errors.
\end{itemize}

\subsection{Image Similarity Metrics}
For both synthetic and real datasets, we compute:

\begin{itemize}
    \item \textbf{Mean Squared Error (MSE)}: The average squared difference between the rendered and target images.
    \item \textbf{Peak Signal-to-Noise Ratio (PSNR)}: A measure of the quality of the rendered image compared to the target image.
    \item \textbf{Structural Similarity Index (SSIM)}: A perceptual metric that quantifies image quality degradation.
    \item \textbf{Mutual Information (MI)}: A measure of the mutual dependence between the rendered and target images.
\end{itemize}

\subsection{Clinical Relevance Metrics}
For the real dataset, we also compute:

\begin{itemize}
    \item \textbf{Target Registration Error (TRE)}: The Euclidean distance between corresponding landmarks in the registered images, measured in millimeters.
    \item \textbf{Dice Coefficient}: The overlap between segmented regions in the registered images.
    \item \textbf{Expert Assessment}: Qualitative evaluation by neurosurgeons on the clinical utility of the registration.
\end{itemize}

\section{Experimental Protocols}

\subsection{Loss Function Comparison}
To evaluate the performance of different loss functions, we conduct the following experiment:

\begin{enumerate}
    \item For each target image in the synthetic dataset:
        \begin{itemize}
            \item Initialize the camera pose with a perturbation from the ground truth
            \item Optimize the pose using each of the following loss functions:
                \begin{itemize}
                    \item L2 Loss
                    \item Weighted L2 Loss
                    \item Normalized Cross-Correlation
                    \item Structural Similarity Index
                    \item Mutual Information
                \end{itemize}
            \item Record the final pose error, image similarity metrics, and convergence behavior
        \end{itemize}
    \item Repeat the experiment for different levels of initial perturbation
    \item Analyze the results to determine which loss function provides the best performance in terms of accuracy, robustness, and convergence speed
\end{enumerate}

\subsection{Hypernetwork Evaluation}
To evaluate the effectiveness of hypernetwork-based style transfer for cross-modal registration, we conduct the following experiment:

\begin{enumerate}
    \item Train hypernetworks using different style encoding methods:
        \begin{itemize}
            \item Y'UV Color Space
            \item Histogram of Oriented Gradients (HOG)
            \item Texture-based Features
            \item Edge Detection and Contour Matching
            \item Gram Matrices
            \item Deep Feature Matching
        \end{itemize}
    \item For each target image in the real dataset:
        \begin{itemize}
            \item Apply each hypernetwork to adapt the NeRF rendering style
            \item Optimize the pose using the best-performing loss function from the previous experiment
            \item Record the final image similarity metrics and clinical relevance metrics
        \end{itemize}
    \item Analyze the results to determine which hypernetwork approach provides the best cross-modal registration performance
\end{enumerate}

\subsection{Initial Pose Sensitivity Analysis}
To evaluate the sensitivity of the registration to the initial pose estimate, we conduct the following experiment:

\begin{enumerate}
    \item For each target image in the synthetic dataset:
        \begin{itemize}
            \item Initialize the camera pose with varying degrees of perturbation from the ground truth
            \item Optimize the pose using the best-performing loss function and hypernetwork approach
            \item Record the final pose error, image similarity metrics, and convergence behavior
        \end{itemize}
    \item Analyze the results to determine the range of initial pose perturbations for which the registration can successfully converge
\end{enumerate}

\subsection{Computational Performance Analysis}
To evaluate the computational requirements and runtime performance of our framework, we conduct the following experiment:

\begin{enumerate}
    \item Measure the following metrics for each combination of loss function and hypernetwork approach:
        \begin{itemize}
            \item Time per iteration
            \item Number of iterations to convergence
            \item Total registration time
            \item Memory usage
            \item GPU utilization
        \end{itemize}
    \item Analyze the results to determine the computational efficiency of different approaches and identify potential bottlenecks
\end{enumerate}

\section{Implementation Details}
All experiments are conducted using the implementation described in Chapter 4, with the following specifications:

\begin{itemize}
    \item \textbf{Hardware}: NVIDIA RTX 3090 GPU, Intel Core i9-10900K CPU, 64GB RAM
    \item \textbf{Software}: PyTorch 1.9.0, CUDA 11.1, Nerfstudio 0.2.0
    \item \textbf{NeRF Model}: Nerfacto with 8 layers, 256 hidden units per layer
    \item \textbf{Optimization}: Adam optimizer with learning rate 0.01, 500 maximum iterations
    \item \textbf{Hypernetwork}: 3-layer MLP with 256, 512, and output dimensions
    \item \textbf{Rendering Resolution}: 256 Ã— 256 pixels
\end{itemize}

\section{Experimental Results Preview}
The results of these experiments are presented and analyzed in the next chapter. We will discuss:

\begin{itemize}
    \item The relative performance of different loss functions for registration accuracy
    \item The effectiveness of hypernetwork-based style transfer for cross-modal registration
    \item The robustness of the registration to initial pose perturbations
    \item The computational efficiency and clinical feasibility of the proposed methods
\end{itemize}

These results will provide insights into the strengths and limitations of NeRF-based intraoperative registration and guide future research in this area. 