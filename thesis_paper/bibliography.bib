@article{Cho2020Enhancing,title={Enhancing Reality: A Systematic Review of Augmented Reality in Neuronavigation and Education.},author={James Cho and S. Rahimpour and Andrew B Cutler and C. Rory Goodwin and S. Lad and P. Codd},journal={World neurosurgery},year={2020},doi={10.1016/j.wneu.2020.04.043}}

@article{Riva2020Intraoperative,
title={Intraoperative Computed Tomography and Finite Element Modelling for Multimodal Image Fusion in Brain Surgery.},
author={M. Riva and P. Hiepe and M. Frommert and I. Divenuto and L. Gay and T. Sciortino and M. C. Nibali and M. Rossi and F. Pessina and L. Bello},
journal={Operative neurosurgery},
year={2020},
doi={10.1093/ons/opz196}
}

@article{Iversen2018Automatic,
title={Automatic Intraoperative Correction of Brain Shift for Accurate Neuronavigation.},
author={D. H. Iversen and W. Wein and F. Lindseth and G. Unsgård and I. Reinertsen},
journal={World neurosurgery},
year={2018},
volume={120},
pages={ e1071-e1078 },
doi={10.1016/j.wneu.2018.09.012}
}

@article{Gerard2021Brain,title={Brain Shift in Neuronavigation of Brain Tumors: An Updated Review of Intra-Operative Ultrasound Applications},author={I. Gerard and Marta Kersten-Oertel and Jeffery A. Hall and D. Sirhan and D. Collins},journal={Frontiers in Oncology},year={2021},volume={10},doi={10.3389/fonc.2020.618837}}

@article{WEI2024107983,
title = {CT synthesis from MR images using frequency attention conditional generative adversarial network},
journal = {Computers in Biology and Medicine},
volume = {170},
pages = {107983},
year = {2024},
issn = {0010-4825},
doi = {https://doi.org/10.1016/j.compbiomed.2024.107983},
url = {https://www.sciencedirect.com/science/article/pii/S0010482524000672},
author = {Kexin Wei and Weipeng Kong and Liheng Liu and Jian Wang and Baosheng Li and Bo Zhao and Zhenjiang Li and Jian Zhu and Gang Yu},
keywords = {MR, Synthetic CT, Deep learning, Generative adversarial networks, Attention mechanism},
abstract = {Magnetic resonance (MR) image-guided radiotherapy is widely used in the treatment planning of malignant tumors, and MR-only radiotherapy, a representative of this technique, requires synthetic computed tomography (sCT) images for effective radiotherapy planning. Convolutional neural networks (CNN) have shown remarkable performance in generating sCT images. However, CNN-based models tend to synthesize more low-frequency components and the pixel-wise loss function usually used to optimize the model can result in blurred images. To address these problems, a frequency attention conditional generative adversarial network (FACGAN) is proposed in this paper. Specifically, a frequency cycle generative model (FCGM) is designed to enhance the inter-mapping between MR and CT and extract more rich tissue structure information. Additionally, a residual frequency channel attention (RFCA) module is proposed and incorporated into the generator to enhance its ability in perceiving the high-frequency image features. Finally, high-frequency loss (HFL) and cycle consistency high-frequency loss (CHFL) are added to the objective function to optimize the model training. The effectiveness of the proposed model is validated on pelvic and brain datasets and compared with state-of-the-art deep learning models. The results show that FACGAN produces higher-quality sCT images while retaining clearer and richer high-frequency texture information.}
}

@article{Gandhe2018Intraoperative,title={Intraoperative magnetic resonance imaging for neurosurgery – An anaesthesiologist's challenge},author={R. Gandhe and C. Bhave},journal={Indian Journal of Anaesthesia},year={2018},volume={62},pages={411 - 417},doi={10.4103/ija.IJA_29_18}}

@book{latex,
  title = {LaTeX : A Documentation Preparation System User's Guide and Reference Manual},
  publisher = {Addison-Wesley Professional},
  year = {1994},
  author = {Leslie Lamport}
}

@inproceedings{yen2020inerf,
  title={{iNeRF}: Inverting Neural Radiance Fields for Pose Estimation},
  author={Lin Yen-Chen and Pete Florence and Jonathan T. Barron and Alberto Rodriguez and Phillip Isola and Tsung-Yi Lin},
  booktitle={IEEE/RSJ International Conference on Intelligent Robots and Systems ({IROS})},
  year={2021}
}

@article{fehrentz2024intraoperative,
  title={Intraoperative Registration by Cross-Modal Inverse Neural Rendering},
  author={Maximilian Fehrentz and Mohammad Farid Azampour and Reuben Dorent and Hassan Rasheed and Colin Galvin and Alexandra Golby and William M. Wells and Sarah Frisken and Nassir Navab and Nazim Haouchine},
  year={2024},
  eprint={2409.11983},
  archivePrefix={arXiv},
  primaryClass={cs.CV},
  url={https://arxiv.org/abs/2409.11983}
}

@article{mildenhall2020nerf,
  title={NeRF: Representing Scenes as Neural Radiance Fields for View Synthesis},
  author={Ben Mildenhall and Pratul P. Srinivasan and Matthew Tancik and Jonathan T. Barron and Ravi Ramamoorthi and Ren Ng},
  journal={ECCV},
  year={2020}
}

@article{navab2015surgical,
  title={Surgical navigation systems and techniques},
  author={Navab, Nassir and Bloch, Christoph and Wang, Lejing},
  journal={Medical Image Computing and Computer-Assisted Intervention},
  year={2015}
}

@article{muller2022instant,
  title={Instant Neural Graphics Primitives with a Multiresolution Hash Encoding},
  author={Thomas Müller and Alex Evans and Christoph Schied and Alexander Keller},
  journal={ACM Transactions on Graphics},
  volume={41},
  number={4},
  pages={1--15},
  year={2022}
}

@article{nccreg,
  title={Normalized Cross Correlation for Registration},
  author={Penney, Graeme P. and Weese, Jürgen and Little, John A. and Desmedt, Paul and Hill, Derek L.G. and Hawkes, David J.},
  journal={Medical Image Computing and Computer-Assisted Intervention},
  pages={1033--1034},
  year={1998}
}

@article{mi2003,
  title={Mutual Information for Medical Image Processing: A Review},
  author={Pluim, J.P.W. and Maintz, J.B.A. and Viergever, M.A.},
  journal={IEEE Transactions on Medical Imaging},
  volume={22},
  number={8},
  pages={986--1004},
  year={2003}
}

@article{wang2023hypernerf,
  title={HyperNeRF: A Higher-Dimensional Representation for Topologically Varying Neural Radiance Fields},
  author={Wang, Wenqi and Xie, Weidi and Chen, Yijie and Wang, Deng and Cheng, Mingfei and Zhang, Matt and Zhou, Bolei},
  journal={ACM Transactions on Graphics},
  volume={42},
  number={1},
  pages={1--13},
  year={2023}
}

@article{Alam2017Medical,
title={Medical image registration in image guided surgery: Issues, challenges and research opportunities},
author={Fakhre Alam and S. Rahman and S. Ullah and K. Gulati},
journal={Biocybernetics and Biomedical Engineering},
year={2017},
volume={38},
pages={71-89},
doi={10.1016/J.BBE.2017.10.001}
}

@article{Han2018Artificial,
title={Artificial Neural Network: Understanding the Basic Concepts without Mathematics},
author={Su-Hyun Han and K. Kim and Sangyun Kim and Y. Youn},
journal={Dementia and Neurocognitive Disorders},
year={2018},
volume={17},
pages={83 - 89},
doi={10.12779/dnd.2018.17.3.83}
}

@inproceedings{Tancik_2023, series={SIGGRAPH ’23},
   title={Nerfstudio: A Modular Framework for Neural Radiance Field Development},
   url={http://dx.doi.org/10.1145/3588432.3591516},
   DOI={10.1145/3588432.3591516},
   booktitle={Special Interest Group on Computer Graphics and Interactive Techniques Conference Conference Proceedings},
   publisher={ACM},
   author={Tancik, Matthew and Weber, Ethan and Ng, Evonne and Li, Ruilong and Yi, Brent and Wang, Terrance and Kristoffersen, Alexander and Austin, Jake and Salahi, Kamyar and Ahuja, Abhik and Mcallister, David and Kerr, Justin and Kanazawa, Angjoo},
   year={2023},
   month=jul, pages={1–12},
   collection={SIGGRAPH ’23} }

@article{Fitzpatrick1998Predicting,title={Predicting error in rigid-body point-based registration},author={M. Fitzpatrick and Jay B. West and C. Maurer},journal={IEEE Transactions on Medical Imaging},year={1998},volume={17},pages={694-702},doi={10.1109/42.736021}}

@article{CLARKSON2011856,
title = {A comparison of voxel and surface based cortical thickness estimation methods},
journal = {NeuroImage},
volume = {57},
number = {3},
pages = {856-865},
year = {2011},
note = {Special Issue: Educational Neuroscience},
issn = {1053-8119},
doi = {https://doi.org/10.1016/j.neuroimage.2011.05.053},
url = {https://www.sciencedirect.com/science/article/pii/S1053811911005611},
author = {Matthew J. Clarkson and M. Jorge Cardoso and Gerard R. Ridgway and Marc Modat and Kelvin K. Leung and Jonathan D. Rohrer and Nick C. Fox and Sébastien Ourselin},
keywords = {Cortical thickness estimation, Laplacian, Registration, FreeSurfer, Alzheimer's disease, Atrophy},
abstract = {Cortical thickness estimation performed in-vivo via magnetic resonance imaging is an important technique for the diagnosis and understanding of the progression of neurodegenerative diseases. Currently, two different computational paradigms exist, with methods generally classified as either surface or voxel-based. This paper provides a much needed comparison of the surface-based method FreeSurfer and two voxel-based methods using clinical data. We test the effects of computing regional statistics using two different atlases and demonstrate that this makes a significant difference to the cortical thickness results. We assess reproducibility, and show that FreeSurfer has a regional standard deviation of thickness difference on same day scans that is significantly lower than either a Laplacian or Registration based method and discuss the trade off between reproducibility and segmentation accuracy caused by bending energy constraints. We demonstrate that voxel-based methods can detect similar patterns of group-wise differences as well as FreeSurfer in typical applications such as producing group-wise maps of statistically significant thickness change, but that regional statistics can vary between methods. We use a Support Vector Machine to classify patients against controls and did not find statistically significantly different results with voxel based methods compared to FreeSurfer. Finally we assessed longitudinal performance and concluded that currently FreeSurfer provides the most plausible measure of change over time, with further work required for voxel based methods.}
}

@article{Klein2010Evaluation,
title={Evaluation of volume-based and surface-based brain image registration methods},
author={A. Klein and Satrajit S. Ghosh and B. Avants and B. Yeo and B. Fischl and B. Fischl and B. Ardekani and B. Ardekani and J. Gee and J. Mann and R. Parsey},
journal={NeuroImage},
year={2010},
volume={51},
pages={214-220},
doi={10.1016/j.neuroimage.2010.01.091}
}

@article{Xie2023Cross,
author = {Xie, Guoyang and Huang, Yawen and Wang, Jinbao and Lyu, Jiayi and Zheng, Feng and Zheng, Yefeng and Jin, Yaochu},
title = {Cross-modality Neuroimage Synthesis: A Survey},
year = {2023},
issue_date = {March 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {56},
number = {3},
issn = {0360-0300},
url = {https://doi.org/10.1145/3625227},
doi = {10.1145/3625227},
abstract = {Multi-modality imaging improves disease diagnosis and reveals distinct deviations in tissues with anatomical properties. The existence of completely aligned and paired multi-modality neuroimaging data has proved its effectiveness in brain research. However, collecting fully aligned and paired data is expensive or even impractical, since it faces many difficulties, including high cost, long acquisition time, image corruption, and privacy issues. An alternative solution is to explore unsupervised or weakly supervised learning methods to synthesize the absent neuroimaging data. In this article, we provide a comprehensive review of cross-modality synthesis for neuroimages, from the perspectives of weakly supervised and unsupervised settings, loss functions, evaluation metrics, imaging modalities, datasets, and downstream applications based on synthesis. We begin by highlighting several opening challenges for cross-modality neuroimage synthesis. Then, we discuss representative architectures of cross-modality synthesis methods under different supervisions. This is followed by a stepwise in-depth analysis to evaluate how cross-modality neuroimage synthesis improves the performance of its downstream tasks. Finally, we summarize the existing research findings and point out future research directions. All resources are available at https://github.com/M-3LAB/awesome-multimodal-brain-image-systhesis.},
journal = {ACM Comput. Surv.},
month = oct,
articleno = {80},
numpages = {28},
keywords = {deep learning, medical image analysis, multi-modality neuroimaging synthesis, Cross-domain}
}

@article{Unberath2021The,
AUTHOR={Unberath, Mathias  and Gao, Cong  and Hu, Yicheng  and Judish, Max  and Taylor, Russell H  and Armand, Mehran  and Grupp, Robert },

TITLE={The Impact of Machine Learning on 2D/3D Registration for Image-Guided Interventions: A Systematic Review and Perspective},

JOURNAL={Frontiers in Robotics and AI},

VOLUME={8},

YEAR={2021},

URL={https://www.frontiersin.org/journals/robotics-and-ai/articles/10.3389/frobt.2021.716007},

DOI={10.3389/frobt.2021.716007},

ISSN={2296-9144},

ABSTRACT={<p>Image-based navigation is widely considered the next frontier of minimally invasive surgery. It is believed that image-based navigation will increase the access to reproducible, safe, and high-precision surgery as it may then be performed at acceptable costs and effort. This is because image-based techniques avoid the need of specialized equipment and seamlessly integrate with contemporary workflows. Furthermore, it is expected that image-based navigation techniques will play a major role in enabling mixed reality environments, as well as autonomous and robot-assisted workflows. A critical component of image guidance is 2D/3D registration, a technique to estimate the spatial relationships between 3D structures, e.g., preoperative volumetric imagery or models of surgical instruments, and 2D images thereof, such as intraoperative X-ray fluoroscopy or endoscopy. While image-based 2D/3D registration is a mature technique, its transition from the bench to the bedside has been restrained by well-known challenges, including brittleness with respect to optimization objective, hyperparameter selection, and initialization, difficulties in dealing with inconsistencies or multiple objects, and limited single-view performance. One reason these challenges persist today is that analytical solutions are likely inadequate considering the complexity, variability, and high-dimensionality of generic 2D/3D registration problems. The recent advent of machine learning-based approaches to imaging problems that, rather than specifying the desired functional mapping, approximate it using highly expressive parametric models holds promise for solving some of the notorious challenges in 2D/3D registration. In this manuscript, we review the impact of machine learning on 2D/3D registration to systematically summarize the recent advances made by introduction of this novel technology. Grounded in these insights, we then offer our perspective on the most pressing needs, significant open problems, and possible next steps.</p>}}

@article{Choe2011Accuracy,
title = {Accuracy of image registration between MRI and light microscopy in the ex vivo brain},
journal = {Magnetic Resonance Imaging},
volume = {29},
number = {5},
pages = {683-692},
year = {2011},
issn = {0730-725X},
doi = {https://doi.org/10.1016/j.mri.2011.02.022},
url = {https://www.sciencedirect.com/science/article/pii/S0730725X11000865},
author = {Ann S. Choe and Yurui Gao and Xia Li and Keegan B. Compton and Iwona Stepniewska and Adam W. Anderson},
keywords = {Image registration, Light microscopy, Brain},
}